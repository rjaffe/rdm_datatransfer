{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDM - Tools for supporting (large) data transfers - excerpts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an experiment -- a notebook to capture practices that support the acceleration of large data transfer (10s of TBs; millions of files) and perhaps automate some or all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this notebook locally on the machine that has to data to transfer. It's written for Mac OS X (Unix/bash). It can probably be easily modified for Linux boxes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Last revised: 27 March 2018\n",
    "\n",
    "By: Rick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To set automagic on, follow the command with the argument '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%automagic 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate the data profiling tools, we'll need a directory with a ton of files. I have one with Library of Congress data on my computer. Locate an appropriate set of sample data on yours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cd /Users/rjaffe/Jupyter_notebooks/RDM_datatransfer/test_data/LOC_Data/batch_az_acacia_ver01/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...count the files (`-type f`), starting from the present working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!find . -type f | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looping one-liners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use looping (and other iterating techniques) to profile the files in a directory tree, recursively from the present working directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a one-liner adapted from a command that John White used recently on Savio. It uses the `ls` command to list the subdirectories in the current directory, then lists the items in each subdirectory and passes the results to `wc` to count them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!for i in `ls`; do echo $i; find $i | wc -l; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some researchers have found that certain file types -- .mat files, for one, apparently -- take a long time to transfer. This variation counts the number of files in each directory with a particular filename extension. (I use .xml as an example only because my test data set contains a number of .xml files.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!for i in `ls`; do echo $i; find $i  -type f -name *.xml | wc -l; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all files with a given filename extension (i.e, of a specific file type)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!find ./sn89053851 -type f -name *.xml  #note the use of '*' as a wildcard, meaning 'any set of characters'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one-liner loops through a given set of values, calling the `find` command to identify files whose size is greater than each value, then pipes that information to `wc` to count those files.  Here, M = megabytes and G = gigabytes.\n",
    "\n",
    "The output shows the number of files of each size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!for size in +0 +1M +10M +1G +10G ; do echo \"$size\"; find . -type f -size $size | wc -l; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `tree` command diagrams the structure of your local file tree. The first argument points to the top of the tree you want to draw. The `-d` flag means 'show only directories' (i.e., not files); the `-o` option writes the output to a local file, which we'll name 'LOCTree.txt'. Writing to a file is valuable because the output can get quite long. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I didn't have the 'tree' package installed on my Mac. I needed to use a package manager to download and install. I use Homebrew (https://brew.sh/), but there are others. To install 'tree' using Homebrew, the command is `brew install tree`. More documentation can be found at https://docs.brew.sh/Manpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!tree ./ -d -o LOCTree.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read the file into the notebook and take a look at the file tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat \"LOCTree.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Running shell scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we run a shell script? Yes. (Of course.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instructions, see: https://www.quora.com/How-do-I-execute-bash-scripts-via-IPython-Jupyter-notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's demonstrate how-to by running a useful script...one that finds all directories with greater than 2000 files and displays the size and name of those directories. \n",
    " \n",
    " First, let's locate the script: it's called 'dirs-gt-2000-du.sh' and it's in the same directory as this notebook. See In[2], above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /Users/rjaffe/Jupyter_notebooks/rdm_datatransfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running scripts within the notebook requires starting a new shell process. There's a library for that: `subprocess`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script takes an argument: the directory that we will profile. We pass both the script name and directory to be profiled as arguments to the subprocess function. \n",
    "\n",
    "Be patient: this will take a while!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirinfo = subprocess.run(['./dirs-gt-2000-du.sh', '/Users/rjaffe/Jupyter_notebooks/rdm_datatransfer/test_data/LOC_Data/batch_az_acacia_ver01', '/dev/null'], stdout=subprocess.PIPE)\n",
    "print(dirinfo.stdout.decode(\"utf-8\", \"strict\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "voilà!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROBLEM: RDM has consulted on several cases in which researchers were trying to upload millions of files to Box or Drive and encountering v-e-r-y slow transfer rates. Also, we've encountered at least two common research tools (Opera Phenix microscopes and FMRIB FSL analysis software) that can produce individual directories containing greater than 20,000 files -- the limit that Box can display without throwing a \"File can't be found' error in response to the MLSD command used by FileZilla and other FTP clients.\n",
    "\n",
    "CONSTRAINTS:\n",
    "\n",
    "• Copying zillions of tiny files (\"ZOTS\") takes much longer than many fewer, larger files. \n",
    "\n",
    "• Google Drive and Box both throttle bulk uploads to as few as two files per second. \n",
    "\n",
    "• Box has a per-file file size limit of 15GB.  \n",
    "\n",
    "CHALLENGE 1: Can we use these tools to devise a strategy for identifying the ends of the tree -- where the number of files tend to be great -- and then tarring or zipping up just those directories? The goal is to enable faster transfer rates to Box and Drive, while allowing researchers to download to their analysis environments only those portions of the data that they need for any given analysis.\n",
    "\n",
    "CHALLENGE 2: Can we run this notebook from the cloud and point it at a local machine with internal or mounted storage to transfer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using rclone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try running rclone to copy a file from the local machine to Google Drive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, navigate to the file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cd /Users/rjaffe/Documents/RDM/TestData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cd Transfer-test-no-subfolders/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ls -al"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run rclone to copy one of the files in this directory to a pre-configured drive account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rclone copy /Users/rjaffe/Documents/RDM/TestData/Transfer-test-no-subfolders/Picture\\ 8.png rclone-rdmconsult-bdrive:test_from_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the drive account in a separate browser to confirm that the file actually transferred. (It did!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Globus and the Globus API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...to be added."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
